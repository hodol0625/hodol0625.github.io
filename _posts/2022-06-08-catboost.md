---
title: "Catboost 활용하기"
comments: true
# other options

  
published: false
---

# Catboost 사용하기

## Introduction

prediction shift 와 target leakage를 해결 하기 위해,

`Ordered Boosting`, `Ordered Target Statistics`를 활용함.


- Prediction shift란?
  - ![img1](/assets/images/prediction_shift.png)
  - 학습데이터에 대한 조건부 확률과, 테스트셋에 대한 조건부 확률이 다르다.

- Target leakeage 란?
  - category 변수를 encoding 하는 방법.
    - one-hot encoding 이 많이 쓰이지만, category 내에 unique한 값의 개수가 많을 수록 즉 cardinality가 높을 수록 sparse 해지는 문제가 생김.
    - embedding 하는 방법이 최근에 많이 사용되지만, 그렇기에는 embedding 모델을 또 개발해야 함.
    - Target statistics 계산
      - mean target value 로 변환
      - ![img2](/assets/images/target_leakage.png)
      - ![img2](/assets/images/target_leakage2.png)
      - 위 문제를 해결하기 위해..
        - Ordered TS 를 제안함.
        - 가사의 시간 개념을 도입해서 객체들을 random permutation을 여러번 하게 됨.
        - ![img2](/assets/images/ordered_ts.png)
        - 이렇게 하면 
          - $x_{k}$ 번째 target statistics 를 계산하는데 $y_{k}$ 정보를 사용하지 않게 된다.
          - 되도록 모든 데이터셋을 활용한다.
        - Ordered Boosting
          - ...

- Ordered Target Statistics
  - 어떻게 target leakeage를 막을 것인가?
  - lightGBM 에서는 feature bundling 방법을 사용했었음.
  - 

- handling missing values
  - cardinalty 가 높은 category 변수를 one-hot encoding 할 때 겪는 문제점 중 하나가 test 셋에 등장하는 새로운 값이다.
    - $ctr_{i} = \frac{prior}{totalCount + 1}$
  - missing value 역시 마찬가지로 계산함


---
Ref
https://www.youtube.com/watch?v=2Yi_Jse_7JQ&t=23s
